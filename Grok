import fitz  # PyMuPDF
import re
from difflib import SequenceMatcher

# ---------------------------
# FILE PATHS
# ---------------------------
NOTICE_PDF = r"C:\Users\Hanumandla Rahul\Desktop\PROXY\notice.pdf"
PROXY_PDF = r"C:\Users\Hanumandla Rahul\Desktop\PROXY\proxy.pdf"
OUTPUT_PDF = r"C:\Users\Hanumandla Rahul\Desktop\PROXY\SMART_QC_REPORT.pdf"

# ---------------------------
# DIMENSIONS (inches → points)
# ---------------------------
def inch_to_pt(x):
    return x * 72

# Notice (2nd page) - narrow to avoid recommendation column
NOTICE_PAGE = 1
NOTICE_Y0 = inch_to_pt(2.9)
NOTICE_Y1 = inch_to_pt(10.0)
NOTICE_X0 = 0
NOTICE_X1 = inch_to_pt(5.5)  # Narrower to exclude "Board Recommends" column

# Proxy (1st page) - full width for searching
PROXY_PAGE = 0
PROXY_Y0 = inch_to_pt(5.7)
PROXY_Y1 = inch_to_pt(10.0)
PROXY_X0 = 0
PROXY_X1 = inch_to_pt(8.0)  # Full width

# ---------------------------
# 1. Extract text from specific area
# ---------------------------
def extract_text_area(pdf_path, page_no, x0, y0, x1, y1):
    doc = fitz.open(pdf_path)
    page = doc[page_no]
    clip = fitz.Rect(x0, y0, x1, y1)
    text = page.get_text("text", clip=clip)
    doc.close()
    return text

# ---------------------------
# 2. Clean boilerplate patterns
# ---------------------------
def clean_text(text):
    """Remove common boilerplate that appears in both docs"""
    # Remove voting instructions
    text = re.sub(r'\bFOR\b\s+\bAGAINST\b\s+\bABSTAIN\b', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\[\s*\]\s*FOR\s*\[\s*\]\s*AGAINST\s*\[\s*\]\s*ABSTAIN', '', text, flags=re.IGNORECASE)
    
    # Remove recommendation phrases
    text = re.sub(r'(?:the\s+)?board(?:\s+of\s+directors)?\s+recommends?\s+(?:a\s+)?vote\s+(?:for|against)[^\n.]*', '', text, flags=re.IGNORECASE)
    text = re.sub(r'recommendation:\s*(?:for|against)', '', text, flags=re.IGNORECASE)
    
    # Remove signature blocks
    text = re.sub(r'signature[:\s]+[_\s]*', '', text, flags=re.IGNORECASE)
    text = re.sub(r'date[:\s]+[_\s]*', '', text, flags=re.IGNORECASE)
    text = re.sub(r'please\s+sign[^\n]*', '', text, flags=re.IGNORECASE)
    
    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

# ---------------------------
# 3. Extract proposals from Notice
# ---------------------------
def extract_notice_items(text):
    """
    Extract numbered items from Notice.
    Returns dict: {label: cleaned_text}
    """
    items = {}
    current_label = None
    current_text = []
    
    # Patterns for proposal numbering
    number_pattern = re.compile(r'^(\d{1,2}[a-z]?[\.)]\s*)', re.MULTILINE)
    
    lines = text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # Check if this line starts a new item
        match = number_pattern.match(line)
        if match:
            # Save previous item
            if current_label and current_text:
                full_text = ' '.join(current_text)
                items[current_label] = clean_text(full_text)
            
            # Start new item
            current_label = match.group(1).strip()
            current_text = [line[match.end():]]
        else:
            # Continue current item
            if current_label:
                current_text.append(line)
    
    # Save last item
    if current_label and current_text:
        full_text = ' '.join(current_text)
        items[current_label] = clean_text(full_text)
    
    return items

# ---------------------------
# 4. Search for Notice text in Proxy
# ---------------------------
def search_in_proxy(notice_text, proxy_full_text):
    """
    Search for the notice text within proxy.
    Returns: (found, similarity, proxy_snippet)
    """
    proxy_clean = clean_text(proxy_full_text)
    notice_clean = notice_text.lower()
    proxy_lower = proxy_clean.lower()
    
    # Direct substring search
    if notice_clean in proxy_lower:
        return (True, 1.0, "Found exact match")
    
    # Fuzzy search - look for high similarity chunks
    notice_words = notice_clean.split()
    if len(notice_words) < 3:
        return (False, 0.0, "Text too short to search")
    
    # Search for key phrases (first 20 words, last 20 words, middle)
    key_phrases = [
        ' '.join(notice_words[:20]),
        ' '.join(notice_words[-20:]) if len(notice_words) > 20 else '',
    ]
    
    best_similarity = 0.0
    best_match = ""
    
    # Sliding window search through proxy
    proxy_words = proxy_lower.split()
    window_size = min(len(notice_words) + 10, len(proxy_words))
    
    for i in range(len(proxy_words) - window_size + 1):
        window = ' '.join(proxy_words[i:i+window_size])
        similarity = SequenceMatcher(None, notice_clean, window).ratio()
        
        if similarity > best_similarity:
            best_similarity = similarity
            # Get original text (not lowercased) for display
            best_match = ' '.join(proxy_full_text.split()[i:i+window_size])
    
    # Check key phrases
    for phrase in key_phrases:
        if phrase and phrase in proxy_lower:
            # Found a key phrase
            if best_similarity < 0.7:
                best_similarity = 0.85
                best_match = "Key phrase found in proxy"
    
    if best_similarity > 0.95:  # Much stricter threshold
        return (True, best_similarity, best_match[:200])
    else:
        return (False, best_similarity, "No match found")

# ---------------------------
# 5. Compare Notice items with Proxy
# ---------------------------
def compare_notice_to_proxy(notice_items, proxy_text):
    """
    For each Notice item, search in Proxy and report findings.
    """
    results = []
    
    for label, notice_content in notice_items.items():
        found, similarity, proxy_snippet = search_in_proxy(notice_content, proxy_text)
        
        if found and similarity >= 0.98:  # Stricter: 98%+ for exact match
            status = "✓ EXACT MATCH"
        elif found and similarity >= 0.95:  # 95-98% = close match
            status = f"⚠ CLOSE MATCH ({similarity:.1%})"
        else:
            status = "✗ NOT FOUND / MISMATCH"
        
        results.append({
            'label': label,
            'status': status,
            'notice_text': notice_content,
            'similarity': similarity,
            'proxy_snippet': proxy_snippet if not found else "Match confirmed"
        })
    
    return results

# ---------------------------
# 6. Generate PDF Report
# ---------------------------
def create_report(results, output_pdf):
    doc = fitz.open()
    page = doc.new_page()
    
    y = 40
    left_margin = 40
    right_margin = 550
    max_width = right_margin - left_margin
    
    def add_text(text, size=11, bold=False, color=(0,0,0)):
        nonlocal y, page
        
        if y > 780:
            page = doc.new_page()
            y = 40
        
        font = "hebo" if bold else "helv"
        
        # Word wrap
        words = text.split()
        lines = []
        current = ""
        
        for word in words:
            test = current + " " + word if current else word
            if fitz.get_text_length(test, fontname=font, fontsize=size) <= max_width:
                current = test
            else:
                if current:
                    lines.append(current)
                current = word
        if current:
            lines.append(current)
        
        for line in lines:
            page.insert_text((left_margin, y), line, fontsize=size, fontname=font, color=color)
            y += size + 5
        
        y += 5
    
    # Title
    add_text("NOTICE ↔ PROXY QC REPORT", size=16, bold=True, color=(0,0,0.8))
    add_text(f"Total Items Checked: {len(results)}", size=12, bold=True)
    y += 10
    
    # Summary
    exact = sum(1 for r in results if '✓' in r['status'])
    partial = sum(1 for r in results if '⚠' in r['status'])
    missing = sum(1 for r in results if '✗' in r['status'])
    
    add_text(f"✓ Exact Matches: {exact}", color=(0,0.5,0))
    add_text(f"⚠ Partial Matches: {partial}", color=(0.8,0.5,0))
    add_text(f"✗ Not Found: {missing}", color=(0.8,0,0))
    y += 15
    
    # Detailed results
    add_text("DETAILED FINDINGS:", size=14, bold=True)
    y += 10
    
    for result in results:
        # Item header
        color = (0,0.5,0) if '✓' in result['status'] else (0.8,0,0) if '✗' in result['status'] else (0.8,0.5,0)
        
        add_text(f"Item {result['label']}", size=12, bold=True)
        add_text(f"Status: {result['status']}", color=color)
        
        # Notice text (show FULL text, not truncated)
        add_text("NOTICE TEXT:", size=10, bold=True)
        add_text(result['notice_text'], size=9)
        
        # Findings
        if '✗' in result['status']:
            add_text("⚠ WARNING: This text was NOT found in the Proxy card", size=9, color=(0.8,0,0), bold=True)
        
        y += 15
    
    doc.save(output_pdf)
    doc.close()

# ---------------------------
# MAIN PIPELINE
# ---------------------------
print("="*60)
print("NOTICE → PROXY QC COMPARISON")
print("="*60)

# Extract text from both documents
print("\n[1/4] Extracting text from Notice...")
notice_text = extract_text_area(NOTICE_PDF, NOTICE_PAGE, NOTICE_X0, NOTICE_Y0, NOTICE_X1, NOTICE_Y1)

print("[2/4] Extracting text from Proxy...")
proxy_text = extract_text_area(PROXY_PDF, PROXY_PAGE, PROXY_X0, PROXY_Y0, PROXY_X1, PROXY_Y1)

# Extract items from Notice
print("[3/4] Parsing Notice items...")
notice_items = extract_notice_items(notice_text)
print(f"      Found {len(notice_items)} items in Notice")

# Search each Notice item in Proxy
print("[4/4] Searching for Notice items in Proxy...")
results = compare_notice_to_proxy(notice_items, proxy_text)

# Generate report
print("\n[REPORT] Generating QC report...")
create_report(results, OUTPUT_PDF)

# Summary
print("\n" + "="*60)
print("REPORT GENERATED SUCCESSFULLY!")
print("="*60)
print(f"Output: {OUTPUT_PDF}")

exact = sum(1 for r in results if '✓' in r['status'])
issues = len(results) - exact

print(f"\n✓ Items Found: {exact}/{len(results)}")
if issues > 0:
    print(f"⚠ Items with Issues: {issues}")
print("\nPlease review the PDF for detailed findings.")
